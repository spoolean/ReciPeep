# -*- coding: utf-8 -*-
"""IngredientsIdentifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wj6I9Ke0F_aya5-1Htgm7HcGxL5trnK7

# **Model Building & Training**
"""

from google.colab import drive
drive.mount("/content/gdrive")

!ls "/content/gdrive/MyDrive/Colab Datasets/Ingredients Complete/images/"

#Import libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense
from tensorflow.keras import backend as K

class SmallerVGGNet:
    def build(width, height, depth, classes, finalAct = "softmax"):
        #Initialise model along with input shape
        model = Sequential()
        inputShape = (height, width, depth)
        chanDim = -1

        if K.image_data_format() == "channels_first":
            inputShape = (depth, height, width)
            chanDim = 1

        #CONV -> RELU -> POOL
        model.add(Conv2D(32, (3, 3), padding = "same", input_shape = inputShape))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis = chanDim))
        model.add(MaxPooling2D(pool_size = (3, 3)))
        model.add(Dropout(0.25))

        #Reduce spatial size, but increase depth
        model.add(Conv2D(64, (3, 3), padding = "same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis = chanDim))
        model.add(Conv2D(64, (3, 3), padding = "same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis = chanDim))
        model.add(MaxPooling2D(pool_size = (2, 2)))
        model.add(Dropout(0.25))

        #Reduce spatial size, but increase depth
        model.add(Conv2D(128, (3, 3), padding = "same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis = chanDim))
        model.add(Conv2D(128, (3, 3), padding = "same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis = chanDim))
        model.add(MaxPooling2D(pool_size = (2, 2)))
        model.add(Dropout(0.25))

        #Flatten model
        model.add(Flatten())
        model.add(Dense(1024))
        model.add(Activation("relu"))
        model.add(BatchNormalization())
        model.add(Dropout(0.5))

        #softmax classifier
        model.add(Dense(classes))
        model.add(Activation(finalAct))

        #Return model
        return model

# Commented out IPython magic to ensure Python compatibility.
#Train model on ingredients data
import matplotlib
matplotlib.use("Agg")

#Import libraries
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import img_to_array
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from imutils import paths
import tensorflow as tf
import numpy as np
import random
import cv2
import os

#Function for finding total number of dataset images
def findNumberOfImages(path):
    finalCount = 0
    for folderName in (os.listdir(path)):
        numberOfFiles = len(os.listdir(os.path.join(path, folderName)))
        finalCount += numberOfFiles

    return (finalCount)

#Initialise number of epochs to train for initial learning rate, batch size and image dimensions
EPOCHS = 30
INIT_LR = 1e-3
BS = 32
IMAGE_DIMS = (96, 96, 3)

#disable eager execution
tf.compat.v1.disable_eager_execution()

#Randomly shuffle images
print ("Loading Images...")

finalImagePaths = []
for filename in sorted(os.listdir("/content/gdrive/MyDrive/Colab Datasets/Ingredients Complete/images/")):
    currentImagePaths = sorted(list(paths.list_images("/content/gdrive/MyDrive/Colab Datasets/Ingredients Complete/images/{}".format(filename))))
    random.seed(42)
    random.shuffle(currentImagePaths)
    finalImagePaths.extend(currentImagePaths)

print ("finalImagePaths: ", finalImagePaths)

#Initialise data and labels, then process images
data = []
labels = []
labelNames = []

for foldername in sorted(os.listdir("/content/gdrive/MyDrive/Colab Datasets/Ingredients Complete/images/")):
    labelNames.append(foldername)

print ("Label Names: ", labelNames)

print ("Number of Labels : {}".format(len(labelNames)))

totalImages = findNumberOfImages("/content/gdrive/MyDrive/Colab Datasets/Ingredients Complete/images/")

count = 0

for imagePath in finalImagePaths:
    image = cv2.imread(imagePath)
    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = img_to_array(image)
    data.append(image)
    labels.append(os.path.basename(os.path.dirname(imagePath)))

    count += 1

    if round(((count - 1) / totalImages) * 100) != round((count / totalImages) * 100):
        print('\r', str(round((count / totalImages) * 100)) + "% Complete", end='')

print('\r', "100% Complete", end='')

#Scale raw pixel intensities to value in range 0, 1; convert data and labels to numpy arrays
data = np.array(data, dtype = "float") / 255.0
labels = np.array(labels)
print("\ndata matrix: {} images ({:.2f}MB)".format(len(finalImagePaths), data.nbytes / (1024 * 1000.0)))

#Integer encode
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(labels)

#Binary encode (One hot)
onehot_encoder = OneHotEncoder(sparse=False)
integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)
onehot_encoded = onehot_encoder.fit_transform(integer_encoded)

#Partition data for testing and training, 80% training, 20% testing
(trainX, testX, trainY, testY) = train_test_split(data, onehot_encoded, test_size = 0.2, random_state = 42)

#Construct image generator
aug = ImageDataGenerator(rotation_range = 25, width_shift_range = 0.1, height_shift_range = 0.1, shear_range = 0.2, zoom_range = 0.2,
                         horizontal_flip = True, fill_mode = "nearest")

#Initialise model with sigmoid function
print ("Compiling Model...")
model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0], depth=IMAGE_DIMS[2], classes=len(labelNames), finalAct="sigmoid")

#Initialise optimiser
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)

model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

#Train network
print("Training Network...")
H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS), validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)

#Save model
print("Serializing Network...")
model.save("/content/gdrive/MyDrive/Colab Models/Ingredients/kerasModelComplete.h5", save_format="h5")

#Plot the training loss and accuracy
plt.style.use("ggplot")
plt.figure()
N = EPOCHS
plt.plot(np.arange(0, N), H.history["loss"], label = "train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label = "val_loss")
plt.plot(np.arange(0, N), H.history["accuracy"], label = "train_acc")
plt.plot(np.arange(0, N), H.history["val_accuracy"], label = "val_acc")
plt.title("Train Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="upper left")
plt.savefig("/content/gdrive/MyDrive/Colab Models/Ingredients/plot.png")

"""# **Applying multi-label classification to unseen images**"""

# Commented out IPython magic to ensure Python compatibility.
#Import libraries
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
from google.colab import files
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
import numpy as np
import imutils
import pickle
import cv2
import os

#Load image

#For retrieval from Google Drive folder
#image = cv2.imread("/content/gdrive/MyDrive/Colab Models/Ingredients/UnseenImage/testImage.jpg")

#For manual upload
image = cv2.imread("/content/{}".format((list(files.upload().keys())[0])))

image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
displayOutput = image

#Pre-process image
image = cv2.resize(image, (96, 96))
image = image.astype("float") / 255.0
image = img_to_array(image)
image = np.expand_dims(image, axis = 0)

#Load model
print ("Loading Network...")
model = load_model("/content/gdrive/MyDrive/Colab Models/Ingredients/kerasModelComplete.h5")

#Classify input image
print ("Classifying Image...")
probabilities = model.predict(image)[0]

plt.rcParams["axes.grid"] = False
plt.imshow(displayOutput.astype('uint8'))
plt.show()

#Display output

def printMostLikely():
    highestPercentage = 0.0;
    mostProbableLabel = 0;

    for i in range(len(labelNames)):
        if (probabilities[i] > highestPercentage):
            highestPercentage = probabilities[i]
            mostProbableLabel = i

    print ("Most likely item: ", labelNames[mostProbableLabel], " ({}%)".format(round(probabilities[mostProbableLabel] * 100), 2))

def printAllProbabilities():
    for i in range(len(labelNames)):
        print (labelNames[i] + ": " + str(round((probabilities[i] * 100), 2)) + "%")

printMostLikely()

printAllProbabilities()